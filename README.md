# Projet MÃ©tÃ©o Paris - ML Pipeline

Un projet de machine learning pour la prÃ©diction mÃ©tÃ©orologique Ã  Paris avec une interface Streamlit, des pipelines Airflow et une architecture Docker.

## ğŸš€ Vue d'ensemble

Ce projet implÃ©mente un pipeline complet de machine learning pour prÃ©dire les conditions mÃ©tÃ©orologiques Ã  Paris. Il inclut :

- **ModÃ¨le ML** : Classification des conditions mÃ©tÃ©o (XGBoost)
- **Interface web** : Application Streamlit avec carte interactive
- **Orchestration** : Pipelines Airflow pour l'entraÃ®nement et la prÃ©diction
- **MLOps** : IntÃ©gration MLflow pour le suivi des expÃ©riences
- **Tests** : Suite de tests automatisÃ©s avec pytest

## ğŸ“ Structure du projet

```
â”œâ”€â”€ app/                    # Scripts Python principaux
â”œâ”€â”€ airflow/               # DAGs Airflow
â”œâ”€â”€ streamlit/             # Application web Streamlit
â”œâ”€â”€ mlflow/                # Configuration MLflow
â”œâ”€â”€ data/                  # DonnÃ©es mÃ©tÃ©o
â”œâ”€â”€ tests/                 # Tests unitaires
â”œâ”€â”€ requirements.txt       # DÃ©pendances Python
â”œâ”€â”€ Dockerfile            # Configuration Docker
â””â”€â”€ Jenkinsfile           # Pipeline CI/CD
```

## ğŸ“Š DonnÃ©es

Le projet utilise le fichier `data/weather_paris.csv` contenant :
- TempÃ©rature, humiditÃ©, pression
- Conditions mÃ©tÃ©orologiques
- DonnÃ©es historiques de Paris

## ğŸ›  Technologies utilisÃ©es

- **ML** : scikit-learn, XGBoost, pandas, numpy
- **Interface** : Streamlit, folium (cartes)
- **Orchestration** : Apache Airflow
- **MLOps** : MLflow
- **Cloud** : AWS S3, boto3
- **Tests** : pytest, great_expectations
- **DevOps** : Docker, Jenkins


## ğŸ¯ Utilisation


### Upload vers S3
python app/data_to_s3.py


### 1. EntraÃ®nement du modÃ¨le

```bash
# Version sans MLflow
python app/paris_meteo_no_mlflow.py

# Version avec fusion des donnÃ©es
python app/paris_meteo_fusion.py
```


### 2. Tests
```bash
# Lancer tous les tests
pytest tests/

# Tests spÃ©cifiques
pytest tests/test_paris_meteo_no_mlflow.py
```

### 3. Pipelines Airflow

```bash
cd airflow
docker-compose up -d
```

AccÃ©dez Ã  `http://localhost:8080` pour gÃ©rer les DAGs :


### 4. Airflow Dags
- `paris_meteo_ml_pipeline_dag` : EntraÃ®nement du modÃ¨le
- `real_time_weather_prediction_dag` : PrÃ©dictions temps rÃ©el


## ğŸŒŸ FonctionnalitÃ©s

- âœ… PrÃ©diction des conditions mÃ©tÃ©o (Clear, Clouds, Rain, etc.)
- âœ… Interface web interactive avec carte
- âœ… Pipelines automatisÃ©s d'entraÃ®nement
- âœ… Suivi des expÃ©riences ML
- âœ… Tests automatisÃ©s
- âœ… DÃ©ploiement Docker
- âœ… IntÃ©gration CI/CD

## ğŸ”§ Configuration

1. **Variables d'environnement** : CrÃ©er un fichier `.env` avec vos clÃ©s API
2. **MLflow** : Configurer l'URI de tracking dans les scripts
3. **AWS** : Configurer les credentials pour S3

## ğŸ“ Licence

Ce projet est sous licence MIT.